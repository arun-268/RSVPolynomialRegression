---
title: "Data Analysis and Results"
format: html
editor: visual
---

## Package Loaded:

```{r, echo=TRUE, warning=FALSE}
library(readxl)
library(tidyverse)
library(kableExtra)
```

## Load Dataset:

```{r}
data <- read_excel("/Users/arunraj/Documents/MS Data Science/Advance Statistical Modeling/Week1-Project/PolynomialRegressionArNa/NinaCode/RSVProject/RSVproject2022/RSV Data for the US.xlsx")
data %>% 
    head() %>% 
    kable() %>% 
    kable_styling()

```

## Data Preprocessing

The first thing that we'll do in data preprocessing is to check for missing values.

```{r}
colSums(is.na(data))
```

Our dat does not have missing values, which is good. If theres is missing value, we have to decide to impute the data or exclude the obsevation.

## Removing Outliers

Let's now take a look at the distribution of our data by drawing boxplots.

```{r}
data %>% 
   select_if(is.numeric) %>% 
   boxplot(main = 'Boxplot of parameters', xlab = 'Parameters', ylab = 'RepWeekDate')
```

```{r}
outlier_slag <- min(boxplot(data['PCRDetectionsnumerator'], plot = FALSE)$out)
data.outliers <- data %>% 
   filter(PCRDetectionsnumerator >= outlier_slag)
```

```{r}
data %>% 
    ggplot(aes(x = RepWeekDate, y = PCRDetectionsnumerator)) +
    geom_point() + 
    geom_point(data = data.outliers, aes(x = RepWeekDate, y = PCRDetectionsnumerator), col = 'red') + 
    labs(
        title = 'Distribution of strength : normal vs outlier (red)',
        x = 'RepWeekDate',
        y = 'PCRDetectionsnumerator'
    )
```

## Data Distribution:

```{r}
data %>% 
    select_if(is.numeric) %>% 
    pivot_longer(cols = -'Virus Isolation percent', names_to = 'param') %>% 
    ggplot(aes(x = value)) +
    geom_density() +
    facet_wrap(~param, scales = 'free_x')  +
    labs(
        title = 'Density graph of parameters',
        x = 'Parameters',
        y = 'Week Frequency'
    )
```

```{r}
ggplot(data=data,aes(x=RepWeekDate,y=PCRDetectionsnumerator))+geom_smooth()
```

#### 

#### Structure of the assignment

1.  Load RSV dataset

2.  plot them in scatter plot/graph

3.  Ensure the data is nonlinear and hence we are moving to polynomial regression.

4.  prepare training and test data set

5.  construct a polynomial regression model and ploy them in a graph using ggplot function

6.  use K- means clustering to spilt the data to find which degree of polynomial suits our regression model.

7.  construct a polynomial regression model.

8.  Test the model with some values and find whether fall in the regression lines.

9.  Conclusion.

#### 
