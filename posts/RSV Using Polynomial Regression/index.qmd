---
title: "Respiratory Syncytical Virus(RSV)"
author: "Arun Rajendran & Zhongyi Sun"
date: "2022-11-13"
categories: default
image: "viralinf.jpg"
listing: 
  contents: posts
  type: table
---

### About RSV:

Respiratory syncytial virus (RSV) was discovered in 1956 and has since been recognized as one of the most common causes of childhood illness. It causes annual outbreaks of respiratory illnesses in all age groups. In most regions of the United States, RSV circulation starts in the fall and peaks in the winter, but the timing and severity of RSV season in a given community can vary from year to year. Scientists are developing several vaccines, monoclonal antibodies, and antiviral therapies to help protect infants and young children, pregnant people (to protect their unborn babies), and older adults from severe RSV infection.

### **Clinical Laboratory Testing**

Clinical symptoms of RSV are nonspecific and can overlap with other viral respiratory infections, as well as some bacterial infections. Several types of laboratory tests are available for confirming RSV infection. These tests may be performed on upper and lower respiratory specimens.

The most commonly used types of RSV clinical laboratory tests are

-   Real-time reverse transcriptase-polymerase chain reaction (rRT-PCR), which is more sensitive than culture and antigen testing

-   Antigen testing, which is highly sensitive in children but not sensitive in adults

Less commonly used tests include:

-   Viral culture

-   Serology, which is usually only used for research and surveillance studies

Some tests can differentiate between RSV subtypes (A and B), but the clinical significance of these subtypes is unclear.

#### Package Loaded:

```{r, echo=TRUE}
library(readxl)
library(tidyverse)
library(kableExtra)
```

#### Load Dataset:

```{r}
data <- read_excel("/Users/arunraj/Documents/MS Data Science/Advance Statistical Modeling/Week1-Project/PolynomialRegressionArNa/NinaCode/RSVProject/RSVproject2022/RSV Data for the US.xlsx")
data %>% 
    head() %>% 
    kable() %>% 
    kable_styling()

```

#### Data Preprocessing

The first thing that we'll do in data preprocessing is to check for missing values.

```{r}
colSums(is.na(data))
```

Our dat does not have missing values, which is good. If theres is missing value, we have to decide to impute the data or exclude the obsevation.

#### Removing outliers

Let's now take a look at the distribution of our data by drawing boxplots.

```{r}
data %>% 
   select_if(is.numeric) %>% 
   boxplot(main = 'Boxplot of parameters', xlab = 'Parameters', ylab = 'RepWeekDate')
```

```{r}
outlier_slag <- min(boxplot(data['PCRDetectionsnumerator'], plot = FALSE)$out)
data.outliers <- data %>% 
   filter(PCRDetectionsnumerator >= outlier_slag)
```

```{r}
data %>% 
    ggplot(aes(x = RepWeekDate, y = PCRDetectionsnumerator)) +
    geom_point() + 
    geom_point(data = data.outliers, aes(x = RepWeekDate, y = PCRDetectionsnumerator), col = 'red') + 
    labs(
        title = 'Distribution of strength : normal vs outlier (red)',
        x = 'RepWeekDate',
        y = 'PCRDetectionsnumerator'
    )
```

#### Data Distribution:

```{r}
data %>% 
    select_if(is.numeric) %>% 
    pivot_longer(cols = -'Virus Isolation percent', names_to = 'param') %>% 
    ggplot(aes(x = value)) +
    geom_density() +
    facet_wrap(~param, scales = 'free_x')  +
    labs(
        title = 'Density graph of parameters',
        x = 'Parameters',
        y = 'Week Frequency'
    )
```

```{r}
ggplot(data=data,aes(x=RepWeekDate,y=PCRDetectionsnumerator))+geom_smooth()
```

#### *Why Ploynomial Regression?*

In simple linear regression algorithm only works when the relationship between the data is linear But suppose if we have non-linear data then Linear regression will not capable to draw a best-fit line and It fails in such conditions. consider the below diagram which has a non-linear relationship and you can see the Linear regression results on it, which does not perform well means which do not comes close to reality. Hence, we introduce polynomial regression to overcome this problem, which helps identify the curvilinear relationship between independent and dependent variables.

#### Structure of the assignment

1.  Load RSV dataset

2.  plot them in scatter plot/graph

3.  Ensure the data is nonlinear and hence we are moving to polynomial regression.

4.  prepare training and test data set

5.  construct a polynomial regression model and ploy them in a graph using ggplot function

6.  use K- means clustering to spilt the data to find which degree of polynomial suits our regression model.

7.  construct a polynomial regression model.

8.  Test the model with some values and find whether fall in the regression lines.

9.  Conclusion.

```{=html}
<!-- -->
```

#### References:

-   Posting Github website: https://www.youtube.com/watch?v=YoKjBcuUP0s

-   Data : https://www.cdc.gov/surveillance/nrevss/rsv/natl-trend.html

-   https://rpubs.com/aerlaut/optimizing-concrete-polynomial-regression
